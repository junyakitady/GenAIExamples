{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A5ogaDN6kxNR"
      },
      "source": [
        "# PDF 文書の内容にもとづいて回答するボットの作り方を理解する\n",
        "## はじめに\n",
        "生成 AI や大規模言語モデル （LLM）は、膨大な量のテキストデータのトレーニングを受けており、テキストを生成し、言語を翻訳し、さまざまな種類のクリエイティブ コンテンツを作成し、有益な方法で質問に答えることができます。ただし、LLM には、企業で使用する場合の問題点がいくつかあります。\n",
        "その一つに、生成 AI は誤った情報を含むテキストを生成したり、誤った情報を翻訳したりする可能性があります。企業における生成 AI 利用では、これが問題となることがあります。\n",
        "\n",
        "そこで生成 AI をエンジンとして利用しながら、企業内の信頼のおける情報の中から適切な回答してほしいというユースケースがあります。\n",
        "\n",
        "これを実現する大きな処理の流れは次のようになっています。\n",
        "\n",
        "1.   PDF ファイルを読み込む\n",
        "2.   ページごとでもよいのですが、もう少し細かい単位にテキストを分割する\n",
        "3.   分割したテキスト情報をエンべディング API を利用してベクトル化 / エンべディング\n",
        "4.   ベクトル情報とテキスト情報の関連を保持する\n",
        "5.   ユーザーの問い合わせ内容をベクトル化 / エンべディングする\n",
        "6.   5. のベクトルと最も類似度の高いベクトルを複数個取得する\n",
        "7.   6. のベクトルを生成元のテキスト情報を取得する\n",
        "8.   複数個のテキスト情報をコンテキスト情報として与え、この情報の中から質問の回答を作成するように LLM に問い合わせをする\n",
        "9.   PDF 文書の内容にもとづく回答が得られます\n",
        "\n",
        "これを実現するためにエンべディング、ベクトル検索やコンテンツの保持といった技術要素が必要となりますが、Google Cloud では Vertex AI Search というソリューションを提供しているため、個々の技術要素をバラバラに組み合わせるのではなく、Google の強みである検索技術をとりこんだソリューションを活用して簡単にソリューションを構築することが可能です。\n",
        "\n",
        "ここでは、生成 AI 利用時のフレームワークである LangChain を利用して、Vertex AI Search を利用して企業の信頼するデータソースから情報を取得し、その情報をもとにチャットボット型で質問に回答する流れを確認します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vertex AI Search のセットアップ\n",
        "\n",
        "次に、リンク先の手順に従って Vertex AI Search をセットアップします。\n",
        "\n",
        "[Create and preview a search app for unstructured data from Cloud Storage](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_and_preview_a_search_app_for_unstructured_data_from)\n",
        "\n",
        "パラメーターは以下を指定していることを確認してください。\n",
        "- アプリケーションの種類: 検索\n",
        "- インデックスするデータの種類: 非構造化データ( PDF や HTML )\n",
        "\n",
        "必要に応じて、Cloud Storage にバケットを作成し、回答させたいコンテンツを含む PDF ファイルをアップロードしておきます。\n",
        "このハンズオンでは、次のファイルをアップロードする前提で記載しています。\n",
        " - [Alphabet 2022 10K annual report](https://abc.xyz/assets/9a/bd/838c917c4b4ab21f94e84c3c2c65/goog-10-k-q4-2022.pdf)\n",
        " - [Google Cloud セキュリティ ホワイトペーパー](https://services.google.com/fh/files/misc/security_whitepapers_4_booklet_jp.pdf)\n",
        " - [「Google Cloud Day: Digital '22 - 15 のトピックから学ぶ」🌟eBook](https://lp.cloudplatformonline.com/rs/808-GJW-314/images/Google_ebooks_all_0614.pdf)\n",
        "\n",
        "インデックスの作成にしばらく時間がかかります。Vertex AI Search のプレビュー機能で検索ができるか確認することが可能です。\n",
        "\n",
        "最後に、作成した Search のアプリの「データ」ビューより、作成したデータストアの ID をメモしておきます。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YZN7V8SNq4-s"
      },
      "source": [
        "## 環境セットアップ\n",
        "\n",
        "python のバージョンを確認します。最新の LangChain は `Requires-Python >=3.8.1,<4.0`が前提となっています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svXE7ZWa_sZj"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "opZUiJat_s7V"
      },
      "source": [
        "前提パッケージを導入します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkYAr6d4jNuA"
      },
      "outputs": [],
      "source": [
        "# Install Vertex AI LLM SDK\n",
        "! pip install langchain langchain-google-vertexai langchain-google-community google-cloud-discoveryengine --upgrade --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**※ 注意: ここでカーネルを再起動します。**\n",
        "\n",
        "* Colab の場合、上記のログ、もしくは、ダイアログで \"RESTART RUNTIME\" ボタンが表示された場合、ボタンを押してカーネルをリスタートできます。\n",
        "* Vertex AI Workbench の場合、メニューよりカーネルのリスタートを実行できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QJPoHHSPlMQw"
      },
      "source": [
        "続いて、Google Cloud でプロジェクトを作成し Vertex AI API を有効化します。\n",
        "\n",
        "また、このコードを実行するユーザーに`Vertex AI ユーザー`、`ディスカバリー エンジン閲覧者`のロールを付与します。\n",
        "\n",
        "Colab の場合、以下を実行し Vertex AI API のユーザー権限をもつアカウントでログインします。 Vertex AI Workbench の場合はスキップされます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-IsvQA9mP62"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ytcQ_o2fC3Sm"
      },
      "source": [
        "環境変数などを定義します。 Google Cloud のプロジェクト ID、Vertex AI Search の DATASTORE ID を指定してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou_H3H5FmyLb"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"<your_project_id>\"  # @param {type:\"string\"}\n",
        "DATASTORE_ID = \"<datastore_id>\"  # @param {type:\"string\"}\n",
        "REGION = \"asia-northeast1\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dym2cLCHDPh_"
      },
      "source": [
        "Vertex AI と LangChain のライブラリーの導入を確認します。 LangChain v0.0.208 で動作確認しています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CyuusrQoFVw"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "print(f\"LangChain version: {langchain.__version__}\")\n",
        "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")\n",
        "\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "198MC9RDrcTP"
      },
      "source": [
        "## Vertex AI Gemini API の準備\n",
        "\n",
        "LangChain を利用して Gemini API のText、Chat、Embeddings モデルを取得します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XO9IEnyo25g"
      },
      "outputs": [],
      "source": [
        "from langchain_google_vertexai import VertexAI\n",
        "\n",
        "# Text model instance integrated with LangChain\n",
        "llm = VertexAI(\n",
        "    model_name=\"gemini-1.0-pro\",\n",
        "    max_output_tokens=2048,\n",
        "    temperature=0.5,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ここでは、Vertex AI Search に最大3つの文書、１つの文書から3つの extractive answer を回答するように設定します。\n",
        "\n",
        "※ RAG アプリケーションのコンテキスト情報として渡すチャンクに相当しますので、要件に応じて適宜調整してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6LE-Bsw1OKO"
      },
      "outputs": [],
      "source": [
        "from langchain_google_community import VertexAISearchRetriever\n",
        "\n",
        "# Vertex AI Search retriever\n",
        "retriever = VertexAISearchRetriever(\n",
        "    project_id=PROJECT_ID, data_store_id=DATASTORE_ID, get_extractive_answers=True, max_extractive_answer_count=3, max_documents=3\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "h8WbmIRuaxia"
      },
      "source": [
        "## Vertex AI Search に格納した PDF の内容で Q/A をする\n",
        "\n",
        "ユーザーが質問した質問に対して、Vertex AI Search の検索で取得した類似のテキスト情報の中から回答を出すようにします。この仕組みを簡単に実現するフレームワークとして LangChain の RetrievalQA を利用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lqTUnaD1SUw"
      },
      "outputs": [],
      "source": [
        "# Create chain to answer questions\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Uses LLM to synthesize results from the search index.\n",
        "# We use Gemini API for LLM\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "R-lNIJn5bh0r"
      },
      "source": [
        "ここで質問を定義します。Vertex AI Search に登録した文書にしたがって適宜修正してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJC10UuF1m0W"
      },
      "outputs": [],
      "source": [
        "#query = input(\"Enter query:\")\n",
        "query = \"Cloud Spannerの特徴は？\" # @param {type:\"string\"}\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jE_8aSb_bseS"
      },
      "source": [
        "LLM に直接問い合わせをした場合は、一般の知識に基づいて回答します。その内容を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTgFcvD8brgO"
      },
      "outputs": [],
      "source": [
        "llm.invoke(query)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7Niy8GIieG7u"
      },
      "source": [
        "Vertex AI Search に登録した PDF からの回答はどのようになるでしょう？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUriTu6Zbkqd"
      },
      "outputs": [],
      "source": [
        "response = qa.invoke(query)\n",
        "response[\"result\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WLvzVhKD5LYV"
      },
      "source": [
        "回答内容を作成したソースを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTiKPdEikE1F"
      },
      "outputs": [],
      "source": [
        "response[\"source_documents\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc1KGL8510vo"
      },
      "source": [
        "どうして PDF の内容をもとに回答しているかを理解するには、上で利用した LangChain の RetrievalQA の `stuff` タイプのソースコードを参照するのが分かりやすいです。\n",
        "\n",
        "https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/question_answering/stuff_prompt.py\n",
        "\n",
        "```\n",
        "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "```\n",
        "訳\n",
        "```\n",
        "次のコンテキストをもとに、最後の質問に答えてください。もし答えが分からない場合は、分からないと答えてください。勝手に答えをでっち上げないでください。\n",
        "```\n",
        "\n",
        "上記のように、最終の回答はプロンプト エンジニアリングで、正確な情報ソースをプロンプトにコンテキスト情報として渡し、そのコンテキスト情報の範囲内で回答するように LLM に依頼しています。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LangChain Expression Language で改良\n",
        "ここでは、上記と同じ処理を LangChain Expression Language (LCEL) で実装した方式に改良します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "template = \"\"\"次のコンテキスト情報を利用して、最後の質問に答えてください。回答は300字程度で回答してください。:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | RunnableParallel({\n",
        "      \"result\": prompt | llm,\n",
        "      \"source_documents\": itemgetter(\"context\"),\n",
        "    })\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chain.invoke(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "以上、ありがとうございました。\n",
        "\n",
        "## 参考情報\n",
        "- [Question Answering Over Documents](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/search/retrieval-augmented-generation/examples/question_answering.ipynb)\n",
        "- [LangChain](https://python.langchain.com/docs/get_started/introduction.html)\n",
        "- [Overview of Generative AI on Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
